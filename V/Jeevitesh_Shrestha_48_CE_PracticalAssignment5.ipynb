{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c66dd70b",
   "metadata": {},
   "source": [
    "# Chapter 6: Exploring Sentence-, Document- and Character-Level                                                    Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95a3688",
   "metadata": {},
   "source": [
    "## Building a Doc2Vec Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac924c6",
   "metadata": {},
   "source": [
    "####  1) Importing the common_texts corpus along with the Doc2Vec and TaggedDocument modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cd2b412",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import common_texts\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ee6a8e",
   "metadata": {},
   "source": [
    "#### 2) Checking the training corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36a00364",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['human', 'interface', 'computer'],\n",
       " ['survey', 'user', 'computer', 'system', 'response', 'time'],\n",
       " ['eps', 'user', 'interface', 'system'],\n",
       " ['system', 'human', 'system', 'eps'],\n",
       " ['user', 'response', 'time'],\n",
       " ['trees'],\n",
       " ['graph', 'trees'],\n",
       " ['graph', 'minors', 'trees'],\n",
       " ['graph', 'minors', 'survey']]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0dbd38",
   "metadata": {},
   "source": [
    "#### 3) Converting the tokenized documents into TaggedDocument format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "301d6f6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TaggedDocument(words=['human', 'interface', 'computer'], tags=[0]),\n",
       " TaggedDocument(words=['survey', 'user', 'computer', 'system', 'response', 'time'], tags=[1]),\n",
       " TaggedDocument(words=['eps', 'user', 'interface', 'system'], tags=[2]),\n",
       " TaggedDocument(words=['system', 'human', 'system', 'eps'], tags=[3]),\n",
       " TaggedDocument(words=['user', 'response', 'time'], tags=[4]),\n",
       " TaggedDocument(words=['trees'], tags=[5]),\n",
       " TaggedDocument(words=['graph', 'trees'], tags=[6]),\n",
       " TaggedDocument(words=['graph', 'minors', 'trees'], tags=[7]),\n",
       " TaggedDocument(words=['graph', 'minors', 'survey'], tags=[8])]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(common_texts)]\n",
    "\n",
    "documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9dbf4e",
   "metadata": {},
   "source": [
    "#### 4) Building and training a basic Doc2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4bcffc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vector_size denotes by how many floating point values will each document will be represented by\n",
    "#the min_count acts as a parameter to set threshold so that only the terms occuring atleast min_count times \n",
    "#will be taken in the vocabulary\n",
    "model = Doc2Vec(documents, vector_size=5, min_count=1, workers=4, epochs = 40)\n",
    "model.train(documents, total_examples=model.corpus_count,epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25204310",
   "metadata": {},
   "source": [
    "#### 5) Validating the vector size for the document embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbe5dd9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.vector_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ed5cc9",
   "metadata": {},
   "source": [
    "#### 6) Checking if the no. of document vectors being built is equal to the no. of documents  used in the training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83cfc8c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.dv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04ad1af",
   "metadata": {},
   "source": [
    "#### 7) Checking the vocabulary and the vocabulary size of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1751b95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#vocab size\n",
    "len(model.wv.index_to_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "065a94ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['system',\n",
       " 'graph',\n",
       " 'trees',\n",
       " 'user',\n",
       " 'minors',\n",
       " 'eps',\n",
       " 'time',\n",
       " 'response',\n",
       " 'survey',\n",
       " 'computer',\n",
       " 'interface',\n",
       " 'human']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#vocabulary\n",
    "model.wv.index_to_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf0537e",
   "metadata": {},
   "source": [
    "#### 8) Building a document vector for a new sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6cbebf64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.05171022 -0.05739109  0.0481263   0.01538622  0.04605532]\n"
     ]
    }
   ],
   "source": [
    "vector = model.infer_vector(['user', 'interface', 'for', 'computer'])\n",
    "print(vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1354c2b",
   "metadata": {},
   "source": [
    "### Changing vector size and min_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047d3f58",
   "metadata": {},
   "source": [
    "#### 1) Building our Doc2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "884c2793",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Doc2Vec(documents, vector_size=50, min_count=3, epochs=40)\n",
    "model.train(documents, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39081a87",
   "metadata": {},
   "source": [
    "#### 2) Checking the vocabulary size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "476ea049",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.wv.index_to_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292f75b1",
   "metadata": {},
   "source": [
    "#### 3) Checking the vocabulary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6be62e1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'system': 0, 'graph': 1, 'trees': 2, 'user': 3}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.key_to_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112cbc0a",
   "metadata": {},
   "source": [
    "#### 4) Building a new paragraph vector using the Doc2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "758ac83f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.00493748 -0.00547006  0.00542764  0.00204919  0.00450158 -0.00186988\n",
      "  0.00702156  0.00560433 -0.00585779  0.00422477 -0.00916069 -0.00756148\n",
      "  0.00802777 -0.00669308 -0.00808496 -0.00552981  0.00827915  0.00071997\n",
      " -0.00040661 -0.00897476  0.0060303  -0.00971152  0.00171542 -0.00404753\n",
      "  0.00748146  0.00549066  0.00172136  0.00109212  0.0071558  -0.0052976\n",
      " -0.00870732 -0.00830556  0.0057922   0.00044906  0.00784768 -0.00902211\n",
      " -0.00028359  0.00934035 -0.00372939 -0.00687985  0.00696723  0.00586227\n",
      " -0.0095457  -0.00774136 -0.00686943 -0.0038848  -0.00944106 -0.00584005\n",
      "  0.00690779  0.00403548]\n"
     ]
    }
   ],
   "source": [
    "vector = model.infer_vector(['user', 'interface', 'for', 'computer'])\n",
    "print(vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6926187a",
   "metadata": {},
   "source": [
    "### The dm parameter for switching between modeling approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b52eb2b",
   "metadata": {},
   "source": [
    "#### Building a PV-DM model (dm = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8abdef4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Doc2Vec(documents, vector_size=50, min_count=2, epochs=40, dm=1)\n",
    "model.train(documents, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b142e80",
   "metadata": {},
   "source": [
    "#### Building a PV-BOW model (dm = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea8b782d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Doc2Vec(documents, vector_size=50, min_count=2, epochs=40, dm=0)\n",
    "model.train(documents, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5d1e80",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "943859e5",
   "metadata": {},
   "source": [
    "### The dm_concat parameter (PV - DM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f669cd9",
   "metadata": {},
   "source": [
    "#### When set to 1, indicates to the algorithm that the context vectors should be concatenated while trying to predict the target word. This leads to building a larger model since multiple word embeddings get concatenated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b9c2cfe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Doc2Vec(documents, vector_size=50, min_count=2, epochs=40, window=2, dm=1, alpha=0.3, \n",
    "                min_alpha=0.05, dm_concat=1)\n",
    "model.train(documents, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cdbcc8a",
   "metadata": {},
   "source": [
    "### The dm_mean parameter (PV - DM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d78216a",
   "metadata": {},
   "source": [
    "#### When set to 1, the mean of the context word vectors is taken.                                                                                                        The sum of the context word vectors is taken into account when set to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "413d9395",
   "metadata": {},
   "outputs": [],
   "source": [
    "#taking mean of context vectors\n",
    "model = Doc2Vec(documents, vector_size=50, min_count=2, epochs=40, window=2, dm=1,\n",
    "dm_concat=0, dm_mean=1, alpha=0.3, min_alpha=0.05)\n",
    "model.train(documents, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f5765b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#taking sum of context vectors\n",
    "model = Doc2Vec(documents, vector_size=50, min_count=2, epochs=40, window=2, dm=1,\n",
    "dm_concat=0, dm_mean=0, alpha=0.3, min_alpha=0.05)\n",
    "model.train(documents, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5398c4bb",
   "metadata": {},
   "source": [
    "### Window Size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43055bf",
   "metadata": {},
   "source": [
    "#### This parameter controls the distance between the word under concentration and the word to be predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9d30f503",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Doc2Vec(documents, vector_size=50, min_count=2, epochs=40, window=2, dm=0)\n",
    "model.train(documents, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a204a0",
   "metadata": {},
   "source": [
    "### Learning Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42d8373",
   "metadata": {},
   "source": [
    "#### With the min_alpha parameter, we can specify what value the learning rate should drop to over the course of training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "04b60537",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Doc2Vec(documents, vector_size=50, min_count=2, epochs=40, window=2, dm=1, alpha=0.3, min_alpha=0.05)\n",
    "model.train(documents, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0bb7933",
   "metadata": {},
   "source": [
    "## Building a fastText Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e62377",
   "metadata": {},
   "source": [
    "#### 1) Importing the necessary libraries and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2aa709ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import FastText\n",
    "from gensim.test.utils import common_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b230ce0",
   "metadata": {},
   "source": [
    "#### 2) Instantiating and training a basic FastText model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8c05d4bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36, 290)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = FastText(vector_size=5, window=3, min_count=1)\n",
    "model.build_vocab(corpus_iterable=common_texts)\n",
    "model.train(corpus_iterable=common_texts, total_examples=len(common_texts), epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0afcd07",
   "metadata": {},
   "source": [
    "#### 3) Validating our vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "51ae5237",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'system': 0,\n",
       " 'graph': 1,\n",
       " 'trees': 2,\n",
       " 'user': 3,\n",
       " 'minors': 4,\n",
       " 'eps': 5,\n",
       " 'time': 6,\n",
       " 'response': 7,\n",
       " 'survey': 8,\n",
       " 'computer': 9,\n",
       " 'interface': 10,\n",
       " 'human': 11}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.key_to_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf293d6",
   "metadata": {},
   "source": [
    "#### Visualizing the vector of the word \"human\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "25e9fce1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.03166138,  0.0232673 ,  0.01241681,  0.00036033,  0.02841444],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv['human']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9243098f",
   "metadata": {},
   "source": [
    "#### 4) Checking for the closest vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b25bc7ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('user', 0.7968782186508179),\n",
       " ('system', 0.17462214827537537),\n",
       " ('response', 0.10433417558670044),\n",
       " ('survey', 0.009605271741747856),\n",
       " ('trees', -0.0764053612947464),\n",
       " ('time', -0.13300469517707825),\n",
       " ('minors', -0.1392730176448822),\n",
       " ('eps', -0.2409365326166153),\n",
       " ('graph', -0.29175299406051636)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['computer', 'interface'], negative=['human'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8765df",
   "metadata": {},
   "source": [
    "#### 5) min_n and max_n parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eb03970d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36, 290)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sets the minimum (min_n) and maximum (max_n) lengths of the character n-grams to build representations.\n",
    "#useing a range of 1-gram to 5-grams to build the fastText model\n",
    "model = FastText(vector_size=5, window=3, min_count=1, min_n=1, max_n=5)\n",
    "model.build_vocab(corpus_iterable=common_texts)\n",
    "model.train(corpus_iterable=common_texts, total_examples=len(common_texts),epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df314110",
   "metadata": {},
   "source": [
    "#### 6) Building a representation of a word that does not occur in the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cc4338d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01833103, -0.02146882,  0.00600104, -0.03445043, -0.01658661],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv['rubber']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fb76fa",
   "metadata": {},
   "source": [
    "#### 7) Using an out-of-vocabulary term in the most_similar function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6872618f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('trees', 0.795038104057312),\n",
       " ('eps', 0.7793108820915222),\n",
       " ('minors', 0.24405993521213531),\n",
       " ('time', 0.16231966018676758),\n",
       " ('user', -0.04820769280195236),\n",
       " ('graph', -0.15672095119953156),\n",
       " ('survey', -0.20417729020118713),\n",
       " ('interface', -0.392148494720459),\n",
       " ('response', -0.6897363662719727),\n",
       " ('system', -0.8435081243515015)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['computer', 'human'], negative=['rubber'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4def0ed2",
   "metadata": {},
   "source": [
    "#### 8) Extending our model so that it incorporates new sentences and vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c9b285db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43, 290)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_to_be_added = [[\"I\", \"am\", \"learning\", \"Natural\", \"Language\",\"Processing\"], \n",
    "                         [\"Natural\", \"Language\", \"Processing\", \"is\", \"cool\"]]\n",
    "model.build_vocab(sentences_to_be_added, update=True)\n",
    "model.train(corpus_iterable=common_texts, total_examples=len(sentences_to_be_added), epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773dd911",
   "metadata": {},
   "source": [
    "## Building a spelling corrector/word suggestion module using fastText"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0bb9381",
   "metadata": {},
   "source": [
    "#### 1) Importing the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "db1ca2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from gensim.models import FastText\n",
    "import io\n",
    "import collections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3aa371a",
   "metadata": {},
   "source": [
    "#### 2) Reading the data into basic data structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d247dd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "data = []\n",
    "with io.open('comment_text.txt', 'r', encoding='utf-8') as file:\n",
    "    for entry in file:\n",
    "        entry = entry.strip()\n",
    "        data.append(entry)\n",
    "        words.extend(entry.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88ffdf8",
   "metadata": {},
   "source": [
    "#### 3) Fetching basic information about the data in terms of the most common words in the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "72b5433d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 445892),\n",
       " ('to', 288753),\n",
       " ('of', 219279),\n",
       " ('and', 207335),\n",
       " ('a', 201765),\n",
       " ('I', 182618),\n",
       " ('is', 164602),\n",
       " ('you', 157025),\n",
       " ('that', 140495),\n",
       " ('in', 130244)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_words = []\n",
    "unique_words = collections.Counter(words)\n",
    "unique_words.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f19164",
   "metadata": {},
   "source": [
    "#### 4) Preprocessing the data using the preprocessing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8975f7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The different process present in the pipeline\n",
    "\n",
    "#tokenizing\n",
    "def tokenizer(corpus, keep_list = []):\n",
    "    cleaned_rows = []\n",
    "    for row in corpus:\n",
    "        qs = []\n",
    "        for word in row.split():\n",
    "            if word not in keep_list:\n",
    "                p1 = re.sub('[^a-zA-Z0-9]', ' ', word).lower()\n",
    "                qs.append(p1)\n",
    "            else : qs.append(word)\n",
    "        cleaned_rows.append(' '.join(qs))\n",
    "    return pd.Series(cleaned_rows)\n",
    "\n",
    "#removing stopwords\n",
    "def remove_stops(corpus):\n",
    "    stop = set(stopwords.words('english'))\n",
    "    corpus = [[word for word in sentence.split() if word not in stop] for sentence in corpus]\n",
    "    return corpus\n",
    "\n",
    "#stemming\n",
    "def stemmer(corpus, stem_type):\n",
    "    if stem_type == 'Porter':\n",
    "        stemmer = PorterStemmer()\n",
    "        corpus = [[stemmer.stem(word) for word in sentence] for sentence in corpus]          \n",
    "\n",
    "    if stem_type == 'Snowball':\n",
    "        stemmer = SnowballStemmer(language='english')\n",
    "        corpus = [' '.join([stemmer.stem(word) for word in sentence]) for sentence in corpus] \n",
    "\n",
    "        return corpus\n",
    "#lemmatization\n",
    "def lemmatizer(corpus):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    corpus = [' '.join([lemmatizer.lemmatize(x, pos = 'v') for x in x]) for x in corpus]\n",
    "    return corpus\n",
    "\n",
    "#function to preprocess\n",
    "def preprocess(corpus, keep_list = [], stemming = False, stem_type = None, lemmatization = False, remove_stopwords = True):\n",
    "    \n",
    "    corpus = tokenizer(corpus, keep_list)\n",
    "    \n",
    "    if remove_stopwords:\n",
    "        corpus = remove_stops(corpus)\n",
    "    \n",
    "    if stemming:\n",
    "        corpus = stemmer(corpus, stem_type)\n",
    "        \n",
    "    if lemmatization:\n",
    "        corpus = lemmatizer(corpus)\n",
    "    \n",
    "    corpus = [' '.join(x) for x in corpus]     \n",
    "    \n",
    "    return corpus  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "73f13af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = preprocess(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ad5cdb1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['comment text',\n",
       " 'explanation',\n",
       " 'edits made username hardcore metallica fan reverted vandalisms closure gas voted new york dolls fac please remove template talk page since retired 89 205 38 27',\n",
       " 'aww matches background colour seemingly stuck thanks talk 21 51 january 11 2016 utc',\n",
       " 'hey man really trying edit war guy constantly removing relevant information talking edits instead talk page seems care formatting actual info',\n",
       " '',\n",
       " '',\n",
       " 'make real suggestions improvement wondered section statistics later subsection types accidents think references may need tidying exact format ie date format etc later one else first preferences formatting style references want please let know',\n",
       " '',\n",
       " 'appears backlog articles review guess may delay reviewer turns listed relevant form eg wikipedia good article nominations transport',\n",
       " 'sir hero chance remember page',\n",
       " '',\n",
       " '',\n",
       " 'congratulations well use tools well talk',\n",
       " 'cocksucker piss around work',\n",
       " 'vandalism matt shirvington article reverted please banned',\n",
       " 'sorry word nonsense offensive anyway intending write anything article wow would jump vandalism merely requesting encyclopedic one use school reference selective breeding page almost stub points animal breeding short messy article gives info must someone around expertise eugenics 93 161 107 169',\n",
       " 'alignment subject contrary dulithgow',\n",
       " '',\n",
       " 'fair use rationale image wonju jpg',\n",
       " '',\n",
       " 'thanks uploading image wonju jpg notice image page specifies image used fair use explanation rationale use wikipedia articles constitutes fair use addition boilerplate fair use template must also write image description page specific explanation rationale using image article consistent fair use',\n",
       " '',\n",
       " 'please go image description page edit include fair use rationale',\n",
       " '',\n",
       " 'uploaded fair use media consider checking specified fair use rationale pages find list image pages edited clicking contributions link located top wikipedia page logged selecting image dropdown box note fair use images uploaded 4 may 2006 lacking explanation deleted one week uploaded described criteria speedy deletion questions please ask media copyright questions page thank talk contribs',\n",
       " 'unspecified source image wonju jpg',\n",
       " '',\n",
       " 'thanks uploading image wonju jpg noticed file description page currently specify created content copyright status unclear create file need specify owner copyright obtained website link website taken together restatement website terms use content usually sufficient information however copyright holder different website publisher copyright also acknowledged',\n",
       " '',\n",
       " 'well adding source please add proper copyright licensing tag file one already created took picture audio video tag used release gfdl believe media meets criteria wikipedia fair use use tag one tags listed wikipedia image copyright tags fair use see wikipedia image copyright tags full list copyright tags use',\n",
       " '',\n",
       " 'uploaded files consider checking specified source tagged find list files uploaded following link unsourced untagged images may deleted one week tagged described criteria speedy deletion image copyrighted non free license per wikipedia fair use image deleted 48 hours questions please ask media copyright questions page thank talk contribs',\n",
       " 'bbq',\n",
       " '',\n",
       " 'man lets discuss maybe phone',\n",
       " 'hey',\n",
       " 'talk',\n",
       " 'exclusive group wp talibans good destroying self appointed purist gang one asks questions abt anti social destructive non contribution wp',\n",
       " '',\n",
       " 'ask sityush clean behavior issue nonsensical warnings',\n",
       " 'start throwing accusations warnings lets review edit making ad hominem attacks going strengthen argument merely make look like abusing power admin',\n",
       " 'edit relevant probably single talked event int news late absence notable since living ex president attend certainly notable dedicating aircracft carrier',\n",
       " 'intend revert edit hopes attracting attention admin willing look issue throw accusations around quite liberally perhaps achieve level civility rational discussion topic resolve matter peacefully',\n",
       " 'oh girl started arguments stuck nose belong believe argument yvesnimmo like said situation settled apologized thanks',\n",
       " '',\n",
       " '',\n",
       " 'juelz santanas age',\n",
       " '',\n",
       " '2002 juelz santana 18 years old came february 18th makes juelz turn 19 making songs diplomats third neff signed cam label roc fella 2003 20 years old coming singles santana town yes born 1983 really could older lloyd banks could 22 birthday passed homie neff 23 years old 1983 2006 juelz death god forbid thinking equals 23 go caculator stop changing year birth god',\n",
       " 'bye',\n",
       " '',\n",
       " 'look come think comming back tosser',\n",
       " 'redirect talk voydan pop georgiev chernodrinski',\n",
       " 'mitsurugi point made sense argue include hindi ryo sakazaki page include information',\n",
       " 'mean bother',\n",
       " '',\n",
       " 'see writing something regarding removing anything posted oh well acctually discuss even better',\n",
       " '',\n",
       " 'like ask take closer look premature wrestling deaths catagory men listed surely men belong together catagory anything think catagory besides delting',\n",
       " '',\n",
       " '',\n",
       " 'regarding recent edits',\n",
       " '',\n",
       " 'please read wp filmplot editing film articles edits simply good entirely many unnecessary details bad writing please stop damage 45',\n",
       " '',\n",
       " 'good know yeah studying deepu',\n",
       " '',\n",
       " '',\n",
       " 'snowflakes always symmetrical',\n",
       " '',\n",
       " 'geometry stated snowflake always six symmetric arms assertion simply true according kenneth libbrecht rather unattractive irregular crystals far common variety http www caltech edu atomic snowcrystals myths myths htm perfection someone really need take look site get facts still see decent number falsities page forgive im new dont want edit anything',\n",
       " '',\n",
       " '',\n",
       " 'signpost 24 september 2012',\n",
       " '',\n",
       " 'read signpost full',\n",
       " 'single page',\n",
       " 'unsubscribe',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'considering 1st paragraph edit',\n",
       " 'understand reasons recent edit article sure data necessarily wrong rather persuaded strategy introducing academic honors first paragraph unhelpful approach specific subject note articles sitting justices similarly enhanced also believe changes improvement',\n",
       " '',\n",
       " 'support view edit reverted would invite anyone visit articles written following pairs jurists',\n",
       " 'a1 benjamin cardozo',\n",
       " 'a2 learned hand',\n",
       " '',\n",
       " 'b1 john marshall harlan',\n",
       " 'b2 john marshall harlan ii',\n",
       " '',\n",
       " 'question becomes would current version wikipedia article one either pair improved academic credentials introductory paragraph think',\n",
       " '',\n",
       " 'perhaps helps repeat wry argument kathleen sullivan stanford law makes suggests harvard law faculty wonder antonin scalia avoided learning others managed grasp processes judging would hope anecdote gently illustrates point',\n",
       " '',\n",
       " 'less humorous even stronger argument one clarence thomas makes mentions wanting return law degree yale',\n",
       " '',\n",
       " 'minimum questioning edit deserves reconsidered',\n",
       " 'radial symmetry',\n",
       " '',\n",
       " 'several extinct lineages included echinodermata bilateral homostelea even asymmetrical cothurnocystis stylophora',\n",
       " '',\n",
       " '',\n",
       " 'need apologize wikipedia article made reconciling knowledge subject different sources done history studies archaeology studies guess could scan page e mail could ask someone translate page',\n",
       " 'yes mother child case michael jackson studied motives reasonings judged upon character harshly wacko jacko tell ignore incriminate going continue refuting bullshit jayjg keeps throwing 18 01 16 jun 2005 utc',\n",
       " '',\n",
       " 'ok take bit work quite picture example base duck',\n",
       " 'barnstar',\n",
       " '',\n",
       " 'real life barnstar lets us stars',\n",
       " '',\n",
       " 'could post block expires funny thing think uncivil',\n",
       " 'sure heading fight freedom contain',\n",
       " 'praise',\n",
       " '',\n",
       " 'looked article 6 months ago much improved',\n",
       " 'able post list quickly already text file hard drive meaning get around updating sound list time',\n",
       " 'far generating interest spent four years trying drum interest freely licensed full length classical music unfortunately attempts failed still effectively one classical music wikiproject interested wikipedia talk wikiproject classical music archive 5 need help 21wikipedia talk wikiproject music archive 3 could use helpwikipedia talk wikiproject music archive 2 raulbot 2c music list really given trying interest others',\n",
       " 'sound list featured digg back http digg com music wikipedia free classical music downloads got 1600 diggs imo impressive',\n",
       " '',\n",
       " 'well process things subpages rfa listed noseptember page find look september 2004 think differences el c sure surprised see block left note c',\n",
       " '',\n",
       " '',\n",
       " 'making straw man argument never claimed donohue position rather practitioners researchers field ignored dsm position exactly quote says also something donohue agrees',\n",
       " '',\n",
       " 'combating notion absurd part claim pedophilia sexual orientation since many researchers hold position would unfair call absurd disorder part divided field argue disorder end day value judgment cantor pointed earlier thread scientific judgement choose make value judgment article stated clearly pretend scientific basis',\n",
       " '',\n",
       " '',\n",
       " 'mainland asia includes lower basin china yangtze river well korea specific fine found citation comprehensive dna study hammer rather generarizations speculation far',\n",
       " '',\n",
       " 'citation yayoi culture brought japan migrants korea turn trace roots southeast asia south china',\n",
       " '',\n",
       " '2005 dna study hammer',\n",
       " 'describes yayoi migration korea based sry 465 genes genes close lineage haplogroups m122 m95',\n",
       " 'reiterates entire haplogroup proposed southeast asian origin definition southeast asia includes southern china hypothesizes dispersals neolithic farmers southeast asia also brought haplogroup lineages korea eventually japan',\n",
       " 'concluding paragraph states propose yayoi chromosomes descend prehistoric farmers origins southeastern asia perhaps going back origin agriculture region',\n",
       " 'hammer dna study based global sample consisted 2 500 males 39 asian populations including six populations sampled across japanese archipelago',\n",
       " '',\n",
       " 'pretty much everyone warren county surrounding regions born glens falls hospital included however sure qualifies anyone glens falls native rachel ray believe actually town lake luzerne preceding unsigned comment added 70 100 229 154 04 28 57 august 19 2007 utc',\n",
       " 'hi explicit block fenian edit warring giant causeway wp made several edits described terrorism',\n",
       " 'notability rurika kasuga',\n",
       " 'tag placed rurika kasuga requesting speedily deleted wikipedia done article seems person group people band club company web content indicate subject notable article subject included wikipedia criteria speedy deletion articles assert notability may deleted time please see guidelines generally accepted notable indicate subject article notable may contest tagging add top page existing db tag leave note article talk page explaining position please remove speedy deletion tag hesitate add information article would confirm subject notability guidelines',\n",
       " '',\n",
       " 'guidelines specific types articles may want check criteria biographies web sites bands companies feel free leave note talk page questions',\n",
       " '',\n",
       " 'sure lead must briefly summarize armenia history simply added found necessary anyone thinks sentence redundant lead welcome remove make edits talk',\n",
       " 'tfd',\n",
       " '',\n",
       " 'think eced think responded without seeing others responses added something response know saw mine c wp chicago wp four',\n",
       " 'gay antisemmitian',\n",
       " '',\n",
       " 'archangel white tiger',\n",
       " '',\n",
       " 'meow greetingshhh',\n",
       " '',\n",
       " 'uh two ways erased comment ww2 holocaust brutally slaying jews gays gypsys slavs anyone',\n",
       " '',\n",
       " '1 anti semitian shave head bald go skinhead meetings',\n",
       " '',\n",
       " '2 doubt words bible homosexuality deadly sin make pentagram tatoo forehead go satanistic masses gay pals',\n",
       " '',\n",
       " '3 first last warning fucking gay appreciate nazi shwain would write page wish talk anymore',\n",
       " '',\n",
       " 'beware dark side',\n",
       " 'fuck filthy mother ass dry',\n",
       " 'sorry',\n",
       " '',\n",
       " 'sorry screwed around someones talk page bad know templates talk page helps assert dominance know bow almighty administrators going go play outside mom 76 122 79 82',\n",
       " 'believe lisak criticism present conforms npv rule lisak neutral point view begin offer polygraph even concerned review polygraph results shocks complainant thinking lies uncovered recantation still perfectly valid know telling truth argue machine investigator also part kanin research followup recanted story possible verify false recantations followups recanted version events matched accused said happened',\n",
       " '',\n",
       " 'arguing lisak respected phd baseless kanin respected phd agree edit neutral possible though apologize still something must done',\n",
       " 'point ammended appropriate encyclopedic notability significance',\n",
       " 'words lazy actually point anything change approach tag goes',\n",
       " '',\n",
       " 'claims stalking absolute rubbish serves aggravate situation assumed good faith good intentions part never suggested seen reason suggest might ulterior motive mass adding links one specific company web page matter ever made suggestion administrative matter even mentioned role clearly party disagreement would rate would conflict interest would ask thus extend good faith toward rather making spurious unfounded accusations chatspy',\n",
       " '',\n",
       " '',\n",
       " 'jmabel regards predominant scholary consensus allegedly claims despite third way rhetoric fascism power functioned rather consistently right wing force far aware owning numerous books subject scholary consensus consensus developed respected scholars fascism write manner bias interest group roger griffin hamish mcdonald roger eatwell zeev sternhell recongise fascism third way references show',\n",
       " '',\n",
       " 'dissenters aware seem think fascism absoutely leftist connections merely radical right system street level socialists want put much distance movements possible course come educated people position write books example even foremost scholary expert fascism former member communist party socialist party italy renzo de felice try cover socialistic origins third way status man wrote definitive seven volume piece mussolini',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'bi said wanted talk',\n",
       " '',\n",
       " 'bottom lead section written',\n",
       " '',\n",
       " 'promoter speculated 1994 skyhook concept could cost competitive realistically thought achievable using space elevator skyhook competitive rotating tether concepts addition rotating skyhook fact deemed engineeringly feasible using presently available materials',\n",
       " '',\n",
       " 'regarding addition rotating skyhook fact deemed engineeringly feasible using presently available materials',\n",
       " '',\n",
       " 'statement appears come ref 3 page 10 full quote',\n",
       " '',\n",
       " 'mass tether alone started exceed 200 times mass payload',\n",
       " 'indication particular scenario considered engineeringly',\n",
       " 'feasible using presently available materials although application might become feasible',\n",
       " 'near future better materials become available higher tensile strengths higher',\n",
       " 'operational temperatures',\n",
       " '',\n",
       " 'goes say',\n",
       " '',\n",
       " 'shall see presently available commercial materials suffice make hastol',\n",
       " 'tethers needed primary message want leave reader',\n",
       " 'need magic materials like buckminster fuller carbon nanotubes make',\n",
       " 'space tether facility hastol system existing materials',\n",
       " '',\n",
       " 'would appear misread reference tether mass 200 times mass payload mass upper limit problem systems tether mass less 200 times payload mass built presently available commercial materials',\n",
       " '',\n",
       " 'reinforce conclusion report states',\n",
       " '',\n",
       " 'fundamental conclusion phase hastol study effort concept',\n",
       " 'technically feasible evaluated number alternate system configurations',\n",
       " 'allow hypersonic air breathing vehicle technologies combined orbiting spinning space',\n",
       " 'tether technologies provide method moving payloads surface earth',\n",
       " 'earth orbit one hastol architecture concept developed design',\n",
       " 'solution using existing near term technologies expect number',\n",
       " 'hastol architecture concepts prove similarly technically feasible subjected',\n",
       " 'detailed design studies systems completely reusable potential drastically',\n",
       " 'reducing cost earth orbit space access',\n",
       " '',\n",
       " 'regarding skyhook competitive rotating tether concepts',\n",
       " '',\n",
       " '2000 boeing report possibillity combining skyhooks hypersonic planes concluded general non spinning tether hyperskyhook concept look competitive spinning tether concepts',\n",
       " '',\n",
       " 'full quote',\n",
       " '',\n",
       " 'hyperskyhook',\n",
       " '',\n",
       " '1995 zubrin proposed hypersonic skyhook solution mismatch',\n",
       " 'attainable atmospheric speeds hypersonic airplane orbital speeds space tethers',\n",
       " 'since orbital speed space tether decreases increasing altitu',\n",
       " 'get fucked get fuckeeed got drink cant put get fuck get fucked fucked right',\n",
       " 'threatening disputing neutrality know country quite common bully way discussion push outcomes want russia',\n",
       " 'thanks undeletion hoped researching status texas government including local government copyright status slow going apparently works florida government usually public domain similar article texas guess research old fashioned non lazy actually reliable way ask copyright help desk like suggested meantime using fair use rationale since valid image used article thanks',\n",
       " 'awesome simply disregard notice thanks',\n",
       " 'stupid peace shit stop deleting stuff asshole go die fall hole go hell',\n",
       " 'tony sidaway obviously fistfuckee loves arm ass',\n",
       " '',\n",
       " '',\n",
       " 'ga review ii',\n",
       " '',\n",
       " 'sorry say fail article gan several major problems brought article previous ga assessment issued said article wp lead longer history media attention academics student government demographics trivia additional information section deficient citiations also triva additional information integrated rest article please look wp wiaga fix problem renominate ga class however assessed article b class meet b class criteria regards',\n",
       " 'band page deletion thought gone',\n",
       " '',\n",
       " 'deleting comment posted talk page delete feelings hasty decision delete page sir still cock sucking douche fuck sit back second think life become done take long nope certainly aware life shitstorm sitting front computer masturbating fictional creatures attempts get rid mediocre best constantly sucking dick failure want personal attack huh well bad fuckcock mcdickerson got one go ahead delete profile wikipedia make another one come right back syrthiss talk page insult dick could shatter dreams innocent eighteen year old college freshman trying make name band make happy fucking people overweight single old man dead end job spot perhaps someone else going follow dreams trying hold back somebody else could suffer like yes make empty threats saying anything along lines hurt eat children within sister womb say asshole son bitch mother fucking cock sucker go eat food drown sorrows premature ejaculating bald headed fuck',\n",
       " '',\n",
       " 'something nice maybe go grab couple horny goat weeds local convenience store jack little longer three minutes tonight',\n",
       " '',\n",
       " 'sincerely',\n",
       " 'asshole better every way',\n",
       " 'believe fat artie see recent appearence tonight show jay leno looks absolutely awful put money say artie lange miss candidate 2007 dead pool',\n",
       " '',\n",
       " '',\n",
       " 'kindly keep malicious fingers comment everytime remove repost',\n",
       " 'locking page would also violate wp newbies whether like conservatives wikipedians',\n",
       " 'bisexual like homosexual heterosexual defined sexual activity much like 15 year old boy attracted girl sexually never sex still straight person actually sexually attracted aroused sex well opposite sex bisexual',\n",
       " 'redirect talk frank herbert mason',\n",
       " '',\n",
       " '',\n",
       " 'christian arabs',\n",
       " 'hi could please stop enforcing category christian arabs non arabic christians living middle east wrong middle eastern christians though arabs gone arabization needs stop arabs ethnicity forced called christian arabs christian european born middle east called christian arab reason alone please understand syriac christians e assyrian ancestry speak aramaic though lot forgetting someone speaks aramaic respect fact appease muslims want call everyone arabs middle east closely related arabs saudiarabia ethnicity please stop forcing upon us alien arab ethnicity oppression talk 12 17 26 jun 2007 utc',\n",
       " '',\n",
       " '',\n",
       " 'dh',\n",
       " 'dude abc officially says name episode know already episode name abc says everybody says',\n",
       " 'edits good cunts like revert good edits stupid understand write well revert edits decided bear playground grudge problem maybe one day realise damage noble project 201 215 187 159',\n",
       " '',\n",
       " 'neiln bang harassed edit disruptively get reverted talk',\n",
       " 'went around time certainly case time later stopped taking children young age',\n",
       " 'must chemical imbalance brains ok gibberish guys writing really makes feel sorry ever go law school would legal profession bad',\n",
       " '',\n",
       " '',\n",
       " 'parzival418 trying scare thatso say comments thatso insulting thatso trying suggest original research wikipedia right',\n",
       " '',\n",
       " '',\n",
       " 'oppose article stands properly reference wp reference guidelines issue resolved issues moved mainspace',\n",
       " 'would appreciate apology see unlikely',\n",
       " 'please waste time longer attempts trying justify either plasma physics transgressions toward bother longer issue shall leave alone seek others deserve considerate attention',\n",
       " 'original research pointed episodes',\n",
       " '',\n",
       " 'ambiguous',\n",
       " 'mabuska irish mean one thing qoute thanks preceding unsigned comment added 109 77 58 139',\n",
       " 'course word irish invented establishment irish free state talk',\n",
       " '',\n",
       " 'quote want depends context term used whether applicable note said citizenship ethnicity never mentioned nationality real key meaning nationality meaning term predominantly used form wikipedia nationality terms refers republic ireland already know sure talk',\n",
       " '',\n",
       " 'nationality terms refers republic ireland country nationality terms refers ireland preceding unsigned comment added 109 76 191 188',\n",
       " '',\n",
       " 'oh wow ireland ireland state whose official description republic ireland whats point inane conversation talk',\n",
       " '',\n",
       " 'ireland whose official name ireland preceding unsigned comment added 109 76 191 188',\n",
       " 'http www constitution ie reports constitutionofireland pdf reading also see http www constitution ie reports mbunreachtnaheireann pdf speak preceding unsigned comment added 109 78 224 50',\n",
       " '',\n",
       " 'magazine masthead says time corporate name time inc easily look hand abn amro always corporate name look well',\n",
       " 'take belated piffling prevarications elsewhere late',\n",
       " 'looking looks like around dick talk pages though nothing bad though looks like inability express properly thank concern also cheers',\n",
       " 'direction really necessary name us states recognize give number states american encyclopedia universal one see every single us states recognize named ix',\n",
       " '20 december 2006 utc',\n",
       " '',\n",
       " 'must play metal gear solid 2 often gw arsenal gear went haywire solid snake uploaded emma virus 19 32',\n",
       " 'hi back',\n",
       " 'last warning',\n",
       " 'stop undoing edits die',\n",
       " '',\n",
       " '',\n",
       " 'minimization textile effluent',\n",
       " '',\n",
       " 'proposed deletion template added article minimization textile effluent suggesting deleted according proposed deletion process contributions appreciated article may satisfy wikipedia criteria inclusion deletion notice explain see also wikipedia wikipedia deletion policy may prevent proposed deletion removing notice please explain disagree proposed deletion edit summary talk page also please consider improving article address issues raised even though removing deletion notice prevent deletion proposed deletion process article may still deleted matches speedy deletion criteria sent articles deletion may deleted consensus delete reached agree deletion article person made substantial edits page please add top minimization textile effluent',\n",
       " '',\n",
       " '',\n",
       " 'scientific attribute event cause b cause b deliberate designed sort intelligent intent answer questions beyond',\n",
       " 'well problem answering beyond example completely rigged several major fundamental problems',\n",
       " '',\n",
       " 'first completely fail mention fact intelligence behind id quite literally earth natural science might look honeycomb see built bees find odd looking fossilized honeycomb theorize made odd looking bees fundamentally different saying made something earth id core notion something outside system observe cause science sense word mythology paul bunyan wrestling match babe blue ox kicked much dirt created great lakes evidence paul ox remain mean really',\n",
       " '',\n",
       " 'second natural science takes approach knowledge nothing known scientific law unless irrefutable theories must heavy supporting empirical data back id turns head end run around knowledge plays games probabilities one say flagella bacteria could formed naturally hell id proponents come sort mathematically accurate probability flagella naturally forming bacteria understand statistics id jumps right hurdle takes anything complete detailed natural explanation jams statistics say well improbable happen someone must designed perversion science assign probabilities something understand id making numbers',\n",
       " '',\n",
       " 'finally example b b deliberate design well good rigged example except respect life earth b unknown b example might qualify forensic science dead body b bullet heart see bunch dead bodies bullets heart next time see body bullet heart probably figure killed life earth one scenario cases observe test sense b scientific never actually observed b btw b teh intelligent designer never observed sense science',\n",
       " 'screwjob',\n",
       " '',\n",
       " 'hey noticed comments montreal screwjob discussion page decided since nobody except someone account objected said would atleast change page little make fair wanted tell thought would like know changed words top first paragraph added something second one bothered thats fine thought since fighting nothing even said might aswell tell',\n",
       " 'april 2006',\n",
       " 'thank experimenting page andy griffith wikipedia test worked reverted removed please use sandbox tests want take look welcome page would like learn contributing encyclopedia',\n",
       " '',\n",
       " '',\n",
       " 'christ iq selected therefore every population iq never ceases amaze',\n",
       " '',\n",
       " '',\n",
       " 'prove better knowledge english language would obvious',\n",
       " 'would shut run wikipedia especially stupid kid',\n",
       " 'oh vandalising xd see greetings',\n",
       " 'website',\n",
       " '',\n",
       " 'hey',\n",
       " 'thinking getting website display pictures cheapest thing could find know others fir diliff guys websites think legit could provide better alternatives help guild member also appreciated thanks talk',\n",
       " 'thanks reading',\n",
       " 'personal attacks fruit brute vfd',\n",
       " '',\n",
       " 'apologies critical feel many comments made fruit brute vfd debate far reasonable diplomatic way disagree assertion initial sentence lie makes look even juvenile learn face goofed go long way life attacks age certainly border personal attack bart133 forty sixty eighty would included comment juvenile',\n",
       " '',\n",
       " 'expect apologise anyone want make clear consider comments vfd debate inappropriate think many members community would agree talk 06 46 2005 feb 7 utc',\n",
       " 'transliteration russian place names',\n",
       " 'writing moscow metro malayalam wikipedia finding difficult correctly transliterate russian place names example pronounce park kultury paark kalttari paark kalchchari perhaps something completely different somebody please help transliterating list given https ml wikipedia org wiki putting list want clutter page thanks',\n",
       " '',\n",
       " 'almost got look see real talk',\n",
       " 'one defame someone thinks fort hood shooting justified god law',\n",
       " 'lack balance',\n",
       " '',\n",
       " 'article seriously balance would benefit greatly introduction additional information negative aspects 34 record sort balance problem uncommon dependence works particular author example testing evaluation 34 us army ordnance dept exposed serious problems tank type information included article bring back balance',\n",
       " '',\n",
       " '',\n",
       " 'thanks see violating clearly stated wikipedia policy problem people reviewed elsewhere finishing one wiki project todsy spending rest day important personal blog entry go find discussions james petras fascinating discussion use term jewish lobby put back deleted dissident voice article right away per talk jewish lobby wp v comparing jewish virtual library dissident voice',\n",
       " 'carol moore talk',\n",
       " '',\n",
       " 'hi',\n",
       " 'thanks kind words see around talk',\n",
       " 'collusion poker',\n",
       " '',\n",
       " 'regarded heinous form cheating poker perhaps mention example warranted',\n",
       " 'thanks much however resolved today write anything edit summary camera put ad edit summary box 1equalvoice1 talk',\n",
       " 'right get username able impact saying seem familiar everything probably username get one takes 10 seconds talk contribs',\n",
       " 'however moonlite edit noted golden daph optus wake wikkis funny',\n",
       " 'check following websites',\n",
       " '',\n",
       " 'http www iranchamber com personalities farabi farabi php',\n",
       " 'http www islam org br c2 a0al farabi htm',\n",
       " 'http www superbeyin com sohbet sohbet htm',\n",
       " 'believe one already put page dilbert desktop games',\n",
       " '',\n",
       " '',\n",
       " 'well asked provide diffs within one hour next edit made edit talk page provide diffs requested within one hour edit sanctioned failing provide requested diffs timely manner week still done consequently request lift sanction denied',\n",
       " 'page shoudld important characters reoccur',\n",
       " 'void black doom mephiles etc',\n",
       " 'pair jew hating weiner nazi schmucks',\n",
       " 'tend think list longer rest article problem either history characteristics expanded list culled personally like consensus reached tripel article others included decided country origin highlighted examples trappist abbey foreign foreign includes non belgium examples way article article encyclopedia list people find lists anywhere article reference also style statistics bad say style statistics sounds like prescription description encyclopedia follow latter former used citation follow find valid one style country origin',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'religiously politically motivated push issue please refrain talking page interested otherwise feel free talk relevant edits science deleet talk',\n",
       " '',\n",
       " 'would prefer following users never post',\n",
       " 'maunus aunus snun w',\n",
       " 'weijibaikebianji',\n",
       " '',\n",
       " 'guy published psychology researcher right perhaps know access libraries best sources point often come across mind bendingly condescending also suspect editor racist see wiki 121 134 219 36',\n",
       " 'vandalizing',\n",
       " '',\n",
       " 'fun man sense humor think vandalizing stuff lemonparty org site',\n",
       " 'welcome wikipedia bla discover ekopedia practical encyclopedia alternative life techniques',\n",
       " '',\n",
       " '',\n",
       " 'bla discover ekopedia practical encyclopedia alternative life techniques',\n",
       " 'including appropriate mention solomon article without level support',\n",
       " '',\n",
       " '',\n",
       " 'comment could verify claim talk',\n",
       " '',\n",
       " 'czech republic central europe state article part reason people making confusions especially ridiculous would replace mention north caucasus favor north slope caucasus mountains isnt even geographical area denoting mountains region countries located within continents yet reason refuse allow article denoted continent single factor alone would made massive difference readers tired arguing people essentially wiki squatters refusing nudge given article 24 90 230 216',\n",
       " 'thanks josette enjoyed meeting shocked decision begin reflect consensus one grand poobah make alone serves right stealing time pressing real world duties indulge fun hobby learned lesson waste time like stick fixing little things run across read articles information',\n",
       " 'paleontologists agree organic remains must buried quickly preserved long enough come fossilized however term fossilized precise term several factors metamorphic mineral processes occur organic remains result typically called fossil one major factor concerns kind organisms fossilized vertebrate invertebrates radiolarians sponges plants pollen foot prints etc multiple processes may include permineralization recrystalization carbonization replacement dissolving diagenesis etc talking fossilization complex issue however quick burial questioned',\n",
       " '',\n",
       " 'major question long take processes work organic reamins environment found experimental taphonomy resulted assortment remains becoming fossilized various processes lab course implies given right conditions vast ages issue metamorphic processes ongoing equilibrium met chemical enviroument burial site minerals organic remains flood catastrophic geologists expect organic remains buried flood completely fossilized within one year period flood rather 4000 years processes working much work needs done taphonomy organic remains yet one interprets even results depend upon world view choose believe',\n",
       " 'also think vegetable basket needs wikipedia page',\n",
       " 'bigfoot reference',\n",
       " '',\n",
       " 'magazine better known engineering mining journal may difficult time finding depending live ran across article years ago researching something else made copy clearly derived press accounts treats incident joke whole point citing show incident whatever entirely created 40 years fact leave email scan page email pdf',\n",
       " 'also see cant trust murkoth ramunni',\n",
       " 'http books google com books id hhev0u1gfpec pg pa51 dq thiyya matrilineal hl en sa x ei tlppud2ah8mwiqlgvidgba ved 0cdyq6aewaq v onepage q thiyya 20matrilineal f false',\n",
       " '',\n",
       " '',\n",
       " 'chart performance single ladies put ring',\n",
       " '',\n",
       " 'please take advice split paragraphs section fas generally short paragraphs hard boring ingest much information splitting paragraphs improve flow talk',\n",
       " '',\n",
       " '',\n",
       " 'hahahaha good one',\n",
       " 'removed',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'said temporarily removed requests based cyde advice pending request consensus asked talk page urge anyone reading vote know community wants',\n",
       " 'conformity healthy',\n",
       " '',\n",
       " 'may missed article seem address conformity healthy behaviour way conform grammar understood conform laws recognise need orderly society 194 126 85 214',\n",
       " 'hi new wikipedia read pandemics today impressed quality information knowledge easily available elsewhere easily accessible format thank creating content making accessible',\n",
       " 'say something views educationalist socialist political commentator',\n",
       " '',\n",
       " 'link http www langandlit ualberta ca fall2004 steigelbainbridge html mentions bit stood election candidate respect',\n",
       " 'sandbox',\n",
       " 'take template sandbox says remove reason 11 36 10 jan 2005 utc',\n",
       " '',\n",
       " '',\n",
       " 'heh bit copy wikipedia wikiproject professional wrestling thought look bit tidy better way',\n",
       " 'ahh hello witzeman',\n",
       " '',\n",
       " '203 92 84 161',\n",
       " 'symbols',\n",
       " 'characters',\n",
       " 'greek',\n",
       " 'cyrillic',\n",
       " 'ipa',\n",
       " 'famous article witze happiness wikipedia witzeman great honour passed generations many families regardless race age character knowledge outside world knows little elusive characters honour witzeman ever witzeman said great honour although qualities needed job never disclosed person may witzeman many years called former witzemans via dreams associates witzeman known certain babe cool much lesser known witzewoman',\n",
       " '',\n",
       " 'present witzeman 11 year old boy namely benjamin woods said become witzeman felt awesome radiance top right bumcheek told great number people testimony promised years come',\n",
       " '',\n",
       " 'history',\n",
       " 'present world come enlightned knowledge witzeman present years former witzemen public honour abide formality conservativism time term witzeman compound word adjective witze man witze 11th century term person extreme humour radiant intelligence unfortuneatly witze also sometimes associated bad wind unspeakable reasons',\n",
       " '',\n",
       " 'proper history',\n",
       " 'early 14th century witzemen considered outcasts young children encouraged poke sticks led 1st witzeman rebellion 1555 current witzeman followers attempted coup take local council chess team rebellion disgraced witzeman followers embarassingly pronounced gaga government meeting year period early 1900s dark time witzemans history however good times come witzeman many normal people took part mass demonstrations protests witzeman 1980s building great moment history great rebellion 1988 several witzeman sprinted round visitors gallery house commons wearing clown masks otherwise completely naked thought act circambulation however many people witnessed shocking behaviour mentally spiritually emotionallly scarred life group people included many young children forced go asylums state mental instability suffering trauma time government finally took positive action witzeman 1990 bill rights witzeman signed stating witzemen allowed pleased although formal agreement many journalists viewed letter submission government witzeman behaviour witzeman followers became twisted',\n",
       " '',\n",
       " '',\n",
       " 'ok finished planned cleanup todo page entries removed copied investigated entries page record looked talk',\n",
       " 'dec 14 2006 nist scientist said collapse towers magnitude seismically significant see dr wood scientific method applied thermite hypothesis paper tripod site mp3 links',\n",
       " 'statement drawn watchtower literature honestly clandescently hypocrisy drawn watchtower literature via ray franz arguments literature imposed wikipedia article much coincidence less follower ray franz going come reference wa literature exactly connection ray franz makes without first seen connection made ray franz literature natural',\n",
       " 'nature',\n",
       " 'sorry checked come dulas bay somehow missed dulas disambiguation page completely apologies even getting particularly late night onset swine flu perhaps',\n",
       " 'tcm',\n",
       " '',\n",
       " 'find evidence acupressure tcm rather derived tcm one objects place citation note article',\n",
       " 'well still needs expansion areas citations others images going get pic stanley cup banner tonight hitmen game forgot camera thorough review copy edit someone better flair words work progresses lute',\n",
       " 'redirect somewhere hurt though still think candidates ideal passes notability threshold day basic material still work',\n",
       " 'meivazhi',\n",
       " 'go restarting meivazhi article style standard wikipedia articles someone would probably deleted pretty quickly stayed form posted grateful could help talk meivazhi accuracy',\n",
       " '',\n",
       " 'unfortunately remove links conflict interest guidelines advise editors linking sites also wikipedia attribution policy wp att requires information come third party published sources rather personal websites know good newspaper book accounts meivazhi',\n",
       " '',\n",
       " 'ps salaimanimudi indlist com site personal site member',\n",
       " 'though certainly small article inconsequential warrant subsuming within flame trees article',\n",
       " '',\n",
       " 'discography article stand alone',\n",
       " '',\n",
       " '22 may 2005',\n",
       " 'yeah let merge content sure devil canyon type codename',\n",
       " '',\n",
       " '',\n",
       " 'image yourtransitad jpg',\n",
       " '',\n",
       " 'think may able get better photo ad able okay use replace current one want check first anything',\n",
       " '',\n",
       " '',\n",
       " 'cookie',\n",
       " '',\n",
       " 'cookie',\n",
       " 'lmao n00b go listen manele',\n",
       " '06 29 december 2007 utc',\n",
       " 'yep lol reformist party serbia reformist party another go 20th last parliamentary election winning less votes notable actually mentioned',\n",
       " 'way something little people figured new constitution serbia brought enable kosovo secession 1990 constitution barred possibility kumanovo military technical agreement signed nato fry srs broke coalition sps government collapsed causing new elections unconstitutional act highest treason enough tried maximum sentence radicals demanded death trial serbia tried treason among reasons constitution releases authorities weight go prison recognize form loss sovereignty kosovo 15',\n",
       " 'new wikiproject novels initiative',\n",
       " 'begun new initiative wikiproject novels improvement drive member listed notified please see wikipedia talk wikiproject novels 5 5 5 improvement drive wikipedia wikiproject novels collaboration details also would like remind keep eye project talk page wikipedia talk wikiproject novels thanks',\n",
       " '',\n",
       " '',\n",
       " 'reply',\n",
       " 'facetious would relayed message jza mrsc words stern theres would like evidence claims made talk glad provide also failed provide diffs message regards words claiming offesive perhaps wp assume good faith',\n",
       " '',\n",
       " 'two users constantly harass follow articles making disruptive edits violation numerous wikipedia guidelines wp harass one example removal third party references articles suit pov without entering edit summary considered wikipedia guidelines bad faith violation wp blank violation wp neo adding derogatory neologisms articles organisations personally agree despite made aware policy despite reference said organisation described said neologislm despite community majority constantly removing derogatory term tag team practise shown used numerous editors edit articles british culture trad counties would like evidence ask',\n",
       " '',\n",
       " 'would seem however looking messages talkpage especially lovely intertude uk mediation section jza messaged somebody seems familiar violation wp canvas specifically section wikipedia canvas campaigning may interest going admin may suggest please make familiar policies guidelines referenced message rather accusing user cyberstalked personal attacks systematic bias acceptable make sure policies upheld chip sake friend thanks',\n",
       " 'p polite talk people behind backs please remove comments mrph talk page',\n",
       " '',\n",
       " 'vaughan',\n",
       " 'right went check previous edit found page marvel site spelled vaughn finding many spell correctly thanks edits',\n",
       " '',\n",
       " '',\n",
       " 'block',\n",
       " '',\n",
       " 'hi wondering confirmed darren jolly contestant block',\n",
       " '',\n",
       " 'thanks',\n",
       " '',\n",
       " '',\n",
       " 'opinion please pt ii',\n",
       " '',\n",
       " 'srq continues make personal remarks said may assume help wp rfc u also believe violated 3rr rule today edit warring one accurate word ridiculous edit warring general let make stop may also ask wrong honest statement made talk page mean hasty refactoring appreciate assistance welcome questions btw pivotal accurate well referenced entries become peacock understanding refers unneceessary editorializing precise vital info sequence events thanks',\n",
       " 'azari azerbaijani',\n",
       " '',\n",
       " 'azari iranian azerbaijani turkic nation',\n",
       " 'userbox',\n",
       " 'hello userbox using template user queerrights moved user space per wp gus new link leave questions may still talk page thank',\n",
       " '',\n",
       " '',\n",
       " 'actually take time little bit research bloodofox instead jumping perceive avenue pursue vendetta realised would colleague kiyoweap probability kelpie water horse uisge different terms used different places entity challenged kiyoweap produce something decent uisge guarantee unable corbett',\n",
       " 'seen editors eric elephant room issue baiting poking bear whatever hell want call passive aggressive baiting one wants touch one even though uncivil hell appears tactic choice whenever someone wants get rid someone get way part saddens darkness',\n",
       " '',\n",
       " '',\n",
       " 'socialistm',\n",
       " '',\n",
       " 'two important features smith concept invisible hand first smith advocating social policy people act self interest rather describing observed economic reality people act interest second smith claiming self interest beneficial effects community argue self interest always good merely argued view self interest necessarily bad worth noting upon death smith left much personal wealth charity',\n",
       " '',\n",
       " 'good let make sure put forth idea adam smith socialist wikipedia way',\n",
       " '',\n",
       " '',\n",
       " 'sorry puck one ever said dick number one clearly listed second batman master detective martial artist trained mentioned combat discplines need mention skills abilities battles lost thats encylopia supposed',\n",
       " '',\n",
       " 'also problem going low end showings high end showings proven match meta like slade pinned shiva one earliest appearences',\n",
       " '',\n",
       " 'alpha version multiplayer beta version',\n",
       " '',\n",
       " 'pd seen apart article coat arms sahrawi arab democratic republic also different article named coat arms western sahara shows clearly users politically driven intentions bad faith although claim neutral neutral logically would work coat arms western sahara article intead trying merge two articles messing',\n",
       " '',\n",
       " '',\n",
       " 'treating forum question arose appropriately answered end story',\n",
       " '',\n",
       " '',\n",
       " 'military history wikiproject newsletter issue ii',\n",
       " '',\n",
       " 'april 2006 issue project newsletter may read issue change format future issues delivered following link thanks',\n",
       " 'unblock submission response less 3 minutes proves administrator pay enough attention case',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'request unblocked granted following reason',\n",
       " 'allowing username change gianluigipalermo please put request wikipedia changing username soon possible avoid blocking',\n",
       " '',\n",
       " 'request handled',\n",
       " '',\n",
       " 'unblocking administrator please check active autoblocks user accepting unblock request',\n",
       " 'responded milemoney reasoning edit gave reasoning edit yes absolutely relevant page places discussion income inequality progressive tax article',\n",
       " '',\n",
       " '',\n",
       " 'unblock get lawyers blocking constitutional right free speech',\n",
       " 'attributing classifying personalities',\n",
       " 'invitation input culture lithuania welcomed',\n",
       " 'problems defining personalities attributing certain well known ideological systems may raise propose quite liberal variant definition may connected one certain word necessity however follow certain classifying remains',\n",
       " '',\n",
       " 'initial ideas branch ones concerning period lithuanian national renaissance period artists writers cultural workers period often described modernists definition false concrete things added specifics lithuania',\n",
       " 'distinguish leading ideas nat renaissance later modernism known us cultural aspirations later nat ren may defined modernism cultural context lithuania accented also expression lithuanian cultural heritage expression may seen something simply typically lithuanian mean authors iurlionis seen modernist lithuanian context also even representative lithuanian culture european world wide context parallel example may taken literature india poet tagore well known nobel price winner known us representative culture india making india understandable closer western people concerned main input western culture country seen modernist changing traditional cultural forms especially stagnated ones way also lithuanian cultural leaders n ren could seen modernists broadening cultural forms changing stagnated ones lithuanian context also seen modernists wider context acquainting western people lithuanian culture direct input western culture iurlionis best example',\n",
       " 'way later lithuanian modernists depended mostly later generation approximately 4th decade 20th century concerned part western modernistic movement main purpose looking generally introduce western european ideas lithuanian cultural life see table',\n",
       " 'see two different movements two different world outlooks problem movements collaborated especially political wings interchange ideas well seen many researchers pay attention difference especially soviet period national ideas officially forbidden mixture description movements allowed e g philosopher ram nas bytautas clearly depends first generation often described liberal may understood sense second generation idea liberalism',\n",
       " '',\n",
       " '',\n",
       " 'period generation artists writers philosophers etc context lithuania european context national renaissance period younger generation approx 1905 1930 painter composer iurlionis painter kazys imonis poet philosopher vilius storastas vyd nas dramatist sofija kymantait iurlionien poets adomas jak tas motiejus gustaitis liudas gira composer stasys imkus philosopher ram nas bytautas reformers innovators lithuanian culture representatives lithuanian culture almost unknown period wwi wwii post war years poets v mykolaitis putinas kazys binkis writer ignas einius jurk nas artists ars group philosopher juozas girnius modernists introducing new western ideas lithuanian cultural life central european modernism',\n",
       " 'note lists personalities complete made precisely prominence',\n",
       " '07 51 2004 jul 16 utc',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'actually direct quotes quotation marks attributed generally known plagiarism copyright infringement nyt material issue well know material jewish action taskforce problem',\n",
       " '',\n",
       " 'katelyn faber',\n",
       " 'could weigh bottom talk page katelyn faber regarding inclusion image',\n",
       " '',\n",
       " 'template user totalbox',\n",
       " '',\n",
       " 'thanks reverting',\n",
       " '',\n",
       " 'esperanza newsletter issue 1',\n",
       " 'style border spacing 8px margin 0px 8px width 100',\n",
       " 'class mainpagebg style width 55 border 1px solid cef2e0 background color f5fffa vertical align top color 000',\n",
       " 'reach outreach program aimed allowing users bring issues wikipedia listening sympathetic caring audience',\n",
       " 'one know feel say cannot expect get understanding ask one dispute sometimes life issues much one person fair say sometimes wikipedia problems fall heading place bring bruises sometimes got project attention stress alertsthe stress alerts program aims identifying users stressed alerting community thier stress works tandem stressbusters trying identify causes stress eliminating note editorwelcome new format esperanza newsletter came last advisory council meeting hope like major changes month right council meeting sent include two featured programs sum meeting also signed advisory council members esperanzial end march everyone',\n",
       " 'class mainpagebg style width 45 border 1px solid cedff2 background color f5faff vertical align top',\n",
       " 'width 100 cellpadding 2 cellspacing 5 style vertical align top background color f5faff',\n",
       " 'last ac meeting full log',\n",
       " '',\n",
       " 'style color 000',\n",
       " 'future meetings held monthly fortnightly',\n",
       " 'bans access level changes apart autovoice irc channel reported new log',\n",
       " 'irc channel going one bot time',\n",
       " 'charter requires members 150 edits 2 weeks editing case clarified',\n",
       " 'new code conduct drafted proposed esperanza community',\n",
       " 'npa reform idea dropped officially',\n",
       " 'charter ammendments discussed future voted',\n",
       " 'advisory council going proposed expanded advisory council others want propose listen',\n",
       " '',\n",
       " '',\n",
       " 'fradulent claim',\n",
       " '',\n",
       " 'certainly sockpuppet thechief please retract fradulent claim',\n",
       " 'quick limit discussion changing title considering previous discussions months valid reason move',\n",
       " '',\n",
       " '',\n",
       " '123 18 38 july 18 2005 utc',\n",
       " '',\n",
       " 'p feel free leave message talk page need help anything simply wish say hello',\n",
       " 'course peiser social anthropologist one whose recent research focused primarily social aspects climate change thus least qualified comment state consensus historian regarding study published peer reviewed journal results appeared many reliable sources effect treated differently peiser scientist verbally relayed conclusions directly reporter literally tens thousands wiki articles contain references direct quotes scientists appear source medium reputable reporter',\n",
       " 'hi',\n",
       " '',\n",
       " 'hi good day',\n",
       " '',\n",
       " 'deepest apologies made change',\n",
       " 'made change day',\n",
       " 'day line straightest one straight line',\n",
       " 'biggest brightest highest star sky head',\n",
       " 'clock strikes 12 exactly noon day date provided',\n",
       " 'beautiful thing ever see',\n",
       " 'know many thing need prove know saw day',\n",
       " 'okay black white prove needed',\n",
       " 'sincere apologies trouble cause',\n",
       " '',\n",
       " 'south east asia',\n",
       " 'asia came traditional chinese family',\n",
       " '',\n",
       " 'pleasant day',\n",
       " 'fired moronic wimp lazy research makes sick people like exist world',\n",
       " 'looks like violating wp npa pretty minor point two content conflict try mediation cabal way generally easier sign typing stop irc channel want advice way talk',\n",
       " '',\n",
       " '',\n",
       " 'pat head',\n",
       " 'kc one dedicated wikipedians know madly love give barnstar end chew bury instead let offer metaphorical pat head pup see around tropics',\n",
       " 'note sandbox right place experment thanks',\n",
       " 'friesers opinion simple guess kursk turning point german retreat think hes correct russians personnel improved skill glantz combination forced germans retreat losses problem battle kursk tanks infantry strenghts favor germans weeks kursk german tank strenghters higher kursk zetterling',\n",
       " 'oh know thanks',\n",
       " 'lois roisman',\n",
       " 'piece lois roisman omitted much background everything death updated please review anything want add 67 101 255 166',\n",
       " 'know sex foetus',\n",
       " 'think fagget get oife burn hell hate sorry cant sex running conndoms',\n",
       " '86 29 244 57 86 29 244 57 04 21 14 may 2007',\n",
       " 'sorry link gave dead formatted harvnb plz help matter',\n",
       " 'reply',\n",
       " 'loser un defines vietnam part southeast asia far know vietnam part asean used part french indochina laos shit countries anyway culture always influenced sea han chinese proper yangtze han chinese fringe indigenous tribes guangzhou guangxi',\n",
       " '',\n",
       " 'admit vietnamese bunch wannabe crap people east asian people spoken thinks vietnam integral part sea think backward dirty speak horrible swearing language matter crap spout wikipedia change way people real world think',\n",
       " '',\n",
       " '',\n",
       " '29 august 2006',\n",
       " 'wow understand sentance added crucial really change content community gotten smaller caused automobile sourced statement asked fact information help inform people foresters falls large seemingly peice information article bridges span time 1870 present usfullness edit criteria used determine reverted noted simply added information removed removal frivilous unwarranted problem insist absence statement unjustifiable negligible adding information factual b sourced c informative assume since reason remove first place wiki nazis relax concerned useless edits please see edit fom 26th know carried great infallable mindmatrix imho first useless change',\n",
       " 'stupid fuck',\n",
       " '',\n",
       " 'mother cunt stinks',\n",
       " 'eta john haynes house sarekofvulcan talk',\n",
       " 'new',\n",
       " '',\n",
       " 'userbox',\n",
       " 'tabtab id',\n",
       " 'tabtab id c white',\n",
       " 'tabtab info user faggot',\n",
       " 'tabtab info c lightblue',\n",
       " 'tabtab border c black',\n",
       " 'tabtab usercategory lgbt wikipedians',\n",
       " 'tabtab nocat',\n",
       " 'tabtab',\n",
       " 'tabtab',\n",
       " 'tabtab template automatically categorizes user lgbt',\n",
       " '16 december 2005 utc',\n",
       " 'mendel talk changes mendel refering conspiracy section used 16 53',\n",
       " '',\n",
       " '',\n",
       " 'please vandalize pages edit budweiser anheuser busch continue blocked editing echo',\n",
       " 'correct dead dead however leves wounds hence emphasis serious pov adjective',\n",
       " '',\n",
       " '',\n",
       " 'fixed pic anyone still feels move done voices',\n",
       " 'george w bush approval rating graph',\n",
       " '',\n",
       " 'http upload wikimedia org wikipedia commons 1 10 george w bush approval ratings events svg',\n",
       " '',\n",
       " 'circle september 11th attacks looks far right think could update',\n",
       " '',\n",
       " 'data points post 2005 omitted',\n",
       " '',\n",
       " '',\n",
       " 'sorry interrupt 1200 edits first 200 likely pages asking help much maybe 1000 maybe less still kind counts amulet',\n",
       " 'absolutely use word strongly misleading even like structure nothing mastaba burial chamber basicly mastaba definition entran ceinner space',\n",
       " 'structure one solid pile rocks inner space entrances',\n",
       " 'ment wall fragment',\n",
       " 'noticed neutrality article disputed light ask post invitation discuss whether neutrality achieved deleted highly relevant relatively urgent bearing mind rule emergencies wikipedia time convergence truth achieved',\n",
       " '',\n",
       " 'editors care explanations accompanied reliable published sources could explain thought dogs ate cats would get reception provide sources stop edit warring present sources talk',\n",
       " 'mitch moved yggdrasill',\n",
       " '',\n",
       " 'idea',\n",
       " 'sockpuppets impersonators',\n",
       " '',\n",
       " 'two sockpuppet impersonator accounts including',\n",
       " 'oh also films named three variation thereof listed disambig page wondering makes much sense apologize advance certain individuals sensitive hear truth',\n",
       " 'review request',\n",
       " '',\n",
       " 'hi',\n",
       " '',\n",
       " 'like request klm ga class review anyone seems many similar stuff ga kenya airways ethiopian airlines cheers breaksfixes',\n",
       " 'propose transcribed n article anything brief mention raising trap mouth pre nasal environment would suffice thought american thing raise nasals often hear aussies quite bit well hear english people difference americans tendency diphthongize well raising',\n",
       " 'really surprised broad accent wikipedian saying possible',\n",
       " 'right kind thinking aloud',\n",
       " 'homosexuals intent legitimizing behavior therefore seize opportunity suggest famous persons gay way way life received harmless perfectly normal generations people grow childhood maturity exposed strategy increasingly develop tolerance homosexuality way almost universally accepted diverse alternate behavior way similar religion race nationality lestrade',\n",
       " 'al messier',\n",
       " 'article non notable biography according criteria set wp bio aeropagitica',\n",
       " '',\n",
       " '',\n",
       " 'link sacramento',\n",
       " '',\n",
       " 'placed wikipedia link article word sacramento appears another editor appears stalking reverting everything claims overlinking read policy think understand disagree word sacramento linked anywhere else article made link think link provided good context reader know walnut creek thought maybe knew sacramento anything wrong link would like someone objective give opinions 74 234 45 208',\n",
       " 'blatant pov pushing',\n",
       " '',\n",
       " 'neither guys made contribution italian history article shove unhistorical unconstructive modern pov face',\n",
       " 'history article history',\n",
       " 'heard',\n",
       " 'reason many people get pissed pedantry idiocy triviality wikipedia',\n",
       " 'j sus get f cking life',\n",
       " '',\n",
       " 'reliable sources indicate otherwise please insert personal analysis article talk',\n",
       " 'research thank much relevance article think may reseacrh wp el amke sure realise facts links deleted willing agree people official sites therefore shall delete game site otehrs',\n",
       " '',\n",
       " '',\n",
       " 'totallydisputed notice would probably appropriate given depth disagreement exists cannot understand highlighting statements identified dubious would constitute disfiguring article slimvirgin also used wording recently rather think inaccurate irrelevant information disfigurement template notice',\n",
       " '',\n",
       " 'answer second question side brought forward proposal side yet responded sadly consistent recent patterns delay make comment whether deliberate strategy',\n",
       " 'abused nothing threats extremely disrespectful rules wikipedia ever done tried improve quality wikipedia articles maintain standards quality treated like vandal registered muck articles account blocked administrator',\n",
       " 'give permanat block raseac remember muslims dont worry images trying hurt us cant look images fake nothing islam prophet even article lame wikipedia authentic source encyclopedia kids authenticity anyone edit write whatever think like raeasc see knows islam talks forget wiki lame authenticity recommend add pissed christ jessus article',\n",
       " 'invite',\n",
       " '',\n",
       " '',\n",
       " 'hi still time write articles fundamentals romani culture society would permitted normal presentation beyond stereotypes hope near future manage last discussion managed organize better category romani people country category romani people occupation create articles romani persons',\n",
       " 'asked question recall maybe would make less troubled account',\n",
       " 'says consensus ever reached reverted edits',\n",
       " 'find difficult control emotions still feel mr logy wogy bad',\n",
       " 'fuck block faggot pussy',\n",
       " 'attacking another editor trying make point easy edit wikipedia piece george orwell page proved point common place wikipedians help make better lot lesser bias edits trying mind please could remove warning',\n",
       " '',\n",
       " '',\n",
       " 'please see ref 1 4 5 6 article mentioned wikipedia youngest patent holder india moreover mentioned news latest book real life heroes providing notable reliable reference feel dna group reliable notable reference page exists wikipedia really believe ever ever provide information article bad intentions words sock meatpuppets asked suggested anything edit write free man send information free person analyse wikipedia ref 1 4 5 6 article mentioned wikipedia youngest patent holder india subject speak bad words words verbatim book review repeats india youngest patent holder youngest disabled patent holder world claim bhati supporters pushing fails reliable source discourage people sending information relevant reliable notable122 161 30 232',\n",
       " '',\n",
       " '',\n",
       " 'randroide answers next step',\n",
       " '',\n",
       " 'guys see taking steps wikipedia requests mediation',\n",
       " '',\n",
       " 'job always connect filtered institutional net access following steps could result new undesired controversial truncation words software want happenning',\n",
       " '',\n",
       " 'could please follow instructions link provided thank',\n",
       " '',\n",
       " 'randroide answers new reference burgas00',\n",
       " '',\n",
       " 'last agree something course new section good idea false suicidal terrorists prisa also included',\n",
       " '',\n",
       " 'come oooooon boys start writing section want kudos new proposed article effort made',\n",
       " '',\n",
       " 'remember npov sources sources like citing el pa section doubts genuineness 13th bomb cheers',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'indeed good point remarks cope moral certitudes mariano rajoy published el mundo',\n",
       " '',\n",
       " 'agree 100 larean',\n",
       " '',\n",
       " 'randroide omits mention section 13th bomb added balancing references insisted original version created entirely pov much rest proposed article also sources added el pais available subscribers npov',\n",
       " '',\n",
       " 'right southofwatford randroide omits section',\n",
       " '',\n",
       " 'subscription el pa sorry problem institutional access also advantages like paid access el pa many many publications books one reasons exclusive use filtered internet accesss much easier work due easy availability sources',\n",
       " '',\n",
       " 'see truncation words offsett think better sources',\n",
       " '',\n",
       " 'btw write randroide answers section',\n",
       " 'invading space mind really',\n",
       " 'risking new truncations messages avoid please write outside randroide answers sections',\n",
       " '',\n",
       " 'think proposed article pov work make npov article mine',\n",
       " '',\n",
       " 'take risk truncating reply put short issue whether subscribe el pa whether people read article english wikipedia subscribe sources used accessible readers article putting source readers able see claim article npov mind completely unreasonable',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'sources used accessible readers article',\n",
       " '',\n",
       " 'funny southofwatford',\n",
       " '',\n",
       " 'going follow joke',\n",
       " '',\n",
       " 'please propose also deletion books sources know always someone without book',\n",
       " 'delete references tv radio stations user brazil tv radio home',\n",
       " 'delete references spanish know users know spanish',\n",
       " '',\n",
       " 'pleasure read kind funny jokes really good laugh',\n",
       " '',\n",
       " 'user southofwatford strange find funny sources providing enable users find information sourced deliberately choose sources require users pay see information funny simply bizarre equally english wikipedia would argue choosing spanish foreign language source equally valid source exists english make sense except perhaps busy laughing cynicism evident response',\n",
       " '',\n",
       " '08 3',\n",
       " 'hence removed content nature suitable wikipedia proscribed wp perhaps one sister projects wikia',\n",
       " 'pirating incident',\n",
       " '',\n",
       " 'removed statenment really relate episode much plus kinda topic',\n",
       " 'check http www cla purdue edu blackmon 102cs2001 critical html bio',\n",
       " 'kill niggers',\n",
       " '',\n",
       " 'hard others said included racists sometimes say',\n",
       " 'new user',\n",
       " '',\n",
       " 'hello gogo dodo',\n",
       " '',\n",
       " 'new user wikipedia wanted ask new page could removed deletion list new page kaburst still lot want think reason considered starts like wiktionary yeah give time make better',\n",
       " '',\n",
       " 'thanks',\n",
       " 'regarding edits made december 11 2006 utc jos mourinho',\n",
       " 'thank experimenting wikipedia test worked reverted removed please use sandbox tests may want take look welcome page learn contributing encyclopedia ip address shared multiple users ignore warning make unconstructive edits',\n",
       " '',\n",
       " 'december 2011',\n",
       " '',\n",
       " 'hello welcome although everyone welcome contribute least one recent edits one made smoke bomb edit appear constructive reverted removed thank 1992',\n",
       " 'wrong although blocked occasions never blocked sockpuppetry vandalism disputes multiple topics various socks user hkelkar user vandalpetrol permabanned never used account permitted edit get accounts deleted says indeffed blast',\n",
       " '',\n",
       " '',\n",
       " 'deleted personal attacks',\n",
       " 'please please continue tell really think',\n",
       " '',\n",
       " '',\n",
       " 'important message',\n",
       " '',\n",
       " 'block live',\n",
       " '',\n",
       " 'mess made parker v district columbia wikipedia rise level sophisticated blog',\n",
       " '',\n",
       " 'controversy section belong first place fact non experts issuing warnings indicates wikipedia become sandbox idiots',\n",
       " '',\n",
       " 'sorry polite long short',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'moving talk page',\n",
       " '',\n",
       " 'well see consensus formed show indeed pov bad judgement part thanks comments anyway coldplay exp rt let talk',\n",
       " 'http www users bigpond com montdale page8 html heritage village macedonian sources claim village pure slavic',\n",
       " '',\n",
       " 'organization sub topics culture thrown way towards end economy tourism inappropriate information section unnecessarily loaded history detailed geography makes uninteresting also repetitive information interspersed sub sections without regard whether fit eg geography section starts fact 5th largest state strictly geography belongs introduction climate belongs towards latter part page perhaps toursim regions cities interesting combination case cities uttar pradesh interesting topic several interesting cities regions specialities like copperware moradabad ceramics khurja carpets bhadohi fact remember used information article',\n",
       " 'know answer',\n",
       " '',\n",
       " 'legally possible private citizen violate another private citizen civil rights',\n",
       " 'know section nelson charged federal case anyone could explain would appreciate',\n",
       " '',\n",
       " 'argue whether outcome state murder trial justified really concern since dead letter concerned whether subsequent civil rights prosecution legal state murder acquittal miscarriage justice first time look issei sagawa part mature understanding sort thing realize criminal justice system perfect inevitable innocent people convicted guilty people acquited time time price pay legal system end someone make decision sometimes may necessarily get right think going limb say sagawa case completely beyond reasonable belief',\n",
       " 'burn deck',\n",
       " '',\n",
       " 'guy burn deck like think blrude awakening leviathan motherfucker',\n",
       " 'decesed group members',\n",
       " '',\n",
       " 'seen articles band members name sollowed deceased whats wrong witht little extra information people already know surely main reason articles exist first place even whole wikipedia site exists bad adding word people names longer us factual non opinionative slate anyway',\n",
       " 'fatima bint asad',\n",
       " 'noticed added large chunk article recently could post sources webpages books etc would really helpful thanks 23 56 july 29 2005 utc',\n",
       " '',\n",
       " '',\n",
       " 'added information mayor de blasio announced decisions charter schools someone removed factual information said referenced factual referenced tired add information references successful',\n",
       " '',\n",
       " 'correctly added race sexuality chirlane mccray someone person removed factual information provided charter schools incredibly rude stated vandalism reported descriptions considered negative decides reverted chirlane mccray wikipedia site word black prefer african american mentioned six times sexuality mentioned assertions referenced approved wikipedia site chirlane mccray important writings problem',\n",
       " 'please stop adding nonsense wikipedia considered vandalism would like experiment use sandbox thank 2000',\n",
       " 'well use user page tell meyour gonna remove piss drive nuts also making personal ttack jimmy wales saying bit greedy dont think got 6 million dollars already asking',\n",
       " 'thought would offer advise aswell',\n",
       " '1 wikipedia edit warring',\n",
       " '2 arguing wikipedia administrators',\n",
       " '3 may also remind three revert rule',\n",
       " 'u r tw fuck u gay boy u r smelly fuck ur mum poopie',\n",
       " 'also expressly guidelines sneak disallowed links discussion section froman done youtube propaganda link evidenced throughout page rules seem applied froman go whole hog add feith main page plenty unencyclopedic sources admin seems problem link anonymous left wing blogs whatever care use seems fair game froman 71 100 167 23',\n",
       " 'deletion account',\n",
       " '',\n",
       " 'ok blueboy editing l31 g0ng l41 disabled blueboy96 following reason',\n",
       " '',\n",
       " 'came back 31 hour block picked right back judging history likely get',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'call attention topic resolved matters addressed',\n",
       " '',\n",
       " 'moderators deleting wikipedia history items moderator borgqueen edit cuisine hawaii simply provocation nothing',\n",
       " '',\n",
       " 'reknowned chef pacific rim cuisine cuisine hawaii cuisine hawaii local plate lunch like saying cuisine mexico frozen burritos cuisine canada starbucks pastries cuisine america mcdonald slanderous vicious spiteful',\n",
       " '',\n",
       " 'main point admin question delete history',\n",
       " '',\n",
       " 'resolved problem addressed',\n",
       " '',\n",
       " 'tried discussing user directly account locked',\n",
       " '',\n",
       " 'user open discussion ddebate admin suffers god complex lovcked even editing page hence reason wait unbanned post leving back become corrupt admin fodder back aon topic page thius matter resolved borgqueen subjegate discrimination hazing personal vendettas',\n",
       " '',\n",
       " 'likely get eh buddy',\n",
       " '',\n",
       " 'listen delete user page account wiki grommet going lock keep name content profile',\n",
       " '',\n",
       " 'facade wikipedia good',\n",
       " '',\n",
       " 'delete grommet',\n",
       " '',\n",
       " '',\n",
       " 'listas sabina bavaria',\n",
       " 'bad redirect',\n",
       " 'please remove redirect x 24c page aircraft distinctly different design builder mission etc restore aircrafts unique content page 75 67 80 68',\n",
       " 'info',\n",
       " 'thanks entering article errors corrected would nice simply cut pasted text clear lake article',\n",
       " 'name troy tedford troy telford looking orginal discharge papers right also orginal purple heart 2 olc man war hero biggest world war ever historian history degree recieved dec 04 atu',\n",
       " 'interesting note aircraft landed airfield hawaii',\n",
       " 'thanks fixing exquisite picture',\n",
       " 'would like clamp',\n",
       " 'man also created new words even modern languages already established',\n",
       " '',\n",
       " 'history conveniently contribs thank explanation big deal upset second post waving sneer growing thicker skin finger waggle profanity treating insensate piece internet polemic rather fellow human attempting give honest account account mackensen promptly removed say well understand trying contribute workshop bad idea first place running full tilt tony sidaway managing avoid irc whole month immeasureable improvement quality life anyway always seen somebody stands underdog remember praising addition edit harassment guideline sad see mutuality respect talk',\n",
       " 'type soap box',\n",
       " '',\n",
       " 'yes indeed replaced second one summary women rights talk',\n",
       " 'anyone text search 2 3 see article rely mainly one source publisher fact grand total two citations referencing publisher pure facts issues number items 149 000 parts library',\n",
       " 'gore response',\n",
       " '',\n",
       " 'anybody find gore response bush malaprop gore inventor darn thing club silly one',\n",
       " 'pls give reply yes',\n",
       " '',\n",
       " '',\n",
       " 'neither two added cites support assertion misconception hyphens dashes glyphs remains unsourced near tell one person making claim despite claims consensus unsourced material gets removed wiki policy given month find source reword entry reflects sources actually say restoring citation needed tag source day entry removed',\n",
       " 'short summary referencing essentials',\n",
       " 'faqs organizations',\n",
       " 'noticed also disclosed association frank151 userpage thanks makes working knowing coming lot easier questions review article feel free leave message send email cheers sonia',\n",
       " '',\n",
       " '',\n",
       " 'information already reported fair minded talk refusal allow relevant information factual posted obviously biased party inappropriate representative wikipedia',\n",
       " 'file seankilpatrick2014 jpg file connorbarwincincy png',\n",
       " 'r pat',\n",
       " '',\n",
       " 'thanks copy edit omg reads professional appreciate lot yeah knew would problem okay back story danny body paint robot sketch party theme black light one everybody could see danny still paint washed something sure jack black light switch apartment liz came turned resulted liz paint see whatever said make sense read paint still danny black light attack',\n",
       " 'yeah thought maybe people saw ga note leave message though work user left message regarding article reviewed work future make better still gotten chance see see need know happened stuff well got news lost started watching dvd telling never see wrestling moves cry sad night raw lost cried whatever think cool shawn mind really still see face like quality think play randy like triple h know good crowd still heel ish maybe cause new people heel need faces knows speaking randy today birthday turned 30 well remember first punted victim shawn nice see cody storyline nici welcome danielson miz guess hit',\n",
       " '',\n",
       " 'width 100 style background transparent',\n",
       " 'width 100 style background color',\n",
       " 'style width 50 border 1px solid background color vertical align top',\n",
       " 'hello lceliku welcome wikipedia',\n",
       " 'please remember sign name talk pages clicking using four tildes automatically produce username date also please best always fill edit summary field useful links facilitate involvement',\n",
       " 'happy editing',\n",
       " 'width 100 style background color',\n",
       " 'style width 50 border 0 background color vertical align top',\n",
       " 'getting started introduction',\n",
       " 'five pillars wikipedia',\n",
       " 'edit page',\n",
       " 'intuitive guide wikipedia finding way around table contents',\n",
       " 'department directory editing articles develop article',\n",
       " 'manual style',\n",
       " 'style width 50 border 0 background color vertical align top',\n",
       " 'width 100 cellpadding 2 style vertical align top background color',\n",
       " 'getting help',\n",
       " '',\n",
       " 'style color 000',\n",
       " 'frequently asked questions',\n",
       " 'cheatsheet',\n",
       " 'ask question',\n",
       " 'help pages',\n",
       " 'new contributors help page',\n",
       " 'article wizard wizard help create articles',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '14 07 09 know got big supporter x files like seen almost every episode mention mulder father scull baby',\n",
       " '',\n",
       " 'watched carefully william mulder son frequently referenced final episode top head',\n",
       " '',\n",
       " 'guard thinking',\n",
       " 'mulder son mother',\n",
       " '',\n",
       " 'scully son mulder gave son afraid could never forgive',\n",
       " '',\n",
       " 'mention meaningful looks mulder scully give officiator hearing asks agent scully true mulder lovers got pregnant love child',\n",
       " 'citation r f saumur v city quebec 1953 2 c r 299 endorsement rosemary decaires',\n",
       " 'education',\n",
       " '',\n",
       " 'please keep list colleges pittsburgh list colleges pittsburgh familar area edit list greensburg washington mccandless california pittsburgh please offended enforce also pittsburgh mailing address mean school pittsburgh address extends far place 20 minute ride away',\n",
       " '',\n",
       " 'thanks',\n",
       " 'find way put 25 cites page back throught',\n",
       " 'descendants otman baba trough mehmed ali karako sunni muslim alevis',\n",
       " ...]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4910e0",
   "metadata": {},
   "source": [
    "#### 5) Modifying  data so that it meets fastText requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4d44f61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_data = []\n",
    "for line in data:\n",
    "    if line != \"\":\n",
    "        preprocessed_data.append(line.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4c6478",
   "metadata": {},
   "source": [
    "#### 6) Initializing our fastText model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0dce5d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FastText(vector_size=300, window=3, min_count=1, min_n=1, max_n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b493d4e",
   "metadata": {},
   "source": [
    "#### 7) Building the vocabulary and checking the size of the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5662e130",
   "metadata": {},
   "outputs": [],
   "source": [
    "#building vocabulary\n",
    "model.build_vocab(corpus_iterable=preprocessed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cd22ba1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "182220"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking size of vocabulary\n",
    "len(model.wv.key_to_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a95b51",
   "metadata": {},
   "source": [
    "#### 8) Training our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3bb2712c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55532376, 57208880)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(corpus_iterable = preprocessed_data, total_examples=len(preprocessed_data), epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0461df1b",
   "metadata": {},
   "source": [
    "#### 9) checking if the model can predict the correct spelling for the incorrect words as part of the top 5 similar suggestions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ece1c4ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('xplain', 0.9154737591743469),\n",
       " ('eexplain', 0.9123345017433167),\n",
       " ('plain', 0.9036255478858948),\n",
       " ('exlain', 0.8988020420074463),\n",
       " ('elain', 0.8983729481697083)]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for the word 'explain'\n",
    "model.wv.most_similar('eplain', topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f46cb89d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('rejoinder', 0.9143153429031372),\n",
       " ('remainder', 0.9123693704605103),\n",
       " ('reindeer', 0.9083667993545532),\n",
       " ('reminde', 0.9032237529754639),\n",
       " ('reminders', 0.9031974673271179)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for the word 'reminder'\n",
    "model.wv.most_similar('reminder', topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bd93cd79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('releveant', 0.9456570744514465),\n",
       " ('relent', 0.9408718347549438),\n",
       " ('relevanmt', 0.9396296143531799),\n",
       " ('relevent', 0.9396237730979919),\n",
       " ('relevant', 0.9327782392501831)]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for the word 'relevnt'\n",
    "model.wv.most_similar('relevnt', topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4c758989",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('purpse', 0.9215287566184998),\n",
       " ('cpurse', 0.9101640582084656),\n",
       " ('pure', 0.89461350440979),\n",
       " ('pursue', 0.8822980523109436),\n",
       " ('pulse', 0.8715043663978577)]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for the word 'purse'\n",
    "model.wv.most_similar('purse', topn=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d65d74",
   "metadata": {},
   "source": [
    "## fastText and Document Distances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35ec2fb",
   "metadata": {},
   "source": [
    "#### 1) Initializing the sentences that we want to find  distances between"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c69564e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_1 = \"Obama speaks to the media in Illinois\"\n",
    "sentence_2 = \"President greets the press in Chicago\"\n",
    "sentence_3 = \"Apple is my favorite company\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398494c7",
   "metadata": {},
   "source": [
    "#### 2) Computing the distance between the document pairs using WMD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b628bc10",
   "metadata": {},
   "source": [
    "##### WMD between sentence_1 and sentence_2 using fastText-based vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d9e9f2a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4865180245149761"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_mover_distance = model.wv.wmdistance(sentence_1, sentence_2)\n",
    "word_mover_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5d5f86",
   "metadata": {},
   "source": [
    "##### WMD between sentence_2 and sentence_3 using fastText-based vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d9b958b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6030960327153282"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_mover_distance = model.wv.wmdistance(sentence_2, sentence_3)\n",
    "word_mover_distance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
